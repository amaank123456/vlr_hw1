{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/cmu16824hw1/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from voc_dataset import VOCDataset\n",
    "import utils\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/mnt/data/VOCdevkit/VOC2007/'\n",
    "ann_dir = os.path.join(data_dir, 'Annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split='trainval'\n",
    "split_file = os.path.join(data_dir, 'ImageSets/Main', split + '.txt')\n",
    "with open(split_file) as fp:\n",
    "    index_list = [line.strip() for line in fp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = index_list[0]\n",
    "fpath = os.path.join(ann_dir, index + '.xml')\n",
    "tree = ET.parse(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/cmu16824hw1/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: This method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "root = tree.getroot() # Tree root\n",
    "class_lst = []\n",
    "for child in root:\n",
    "    if child.tag == 'object':\n",
    "        child_lst = child.getchildren()\n",
    "        for item in child_lst:\n",
    "            if item.tag == 'name':\n",
    "                name = item.text\n",
    "            elif item.tag == 'difficult':\n",
    "                difficulty = item.text\n",
    "        class_lst.append((name, difficulty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000005'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chair', '0'),\n",
       " ('chair', '0'),\n",
       " ('chair', '1'),\n",
       " ('chair', '0'),\n",
       " ('chair', '1')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',\n",
    "                   'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "                   'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n"
     ]
    }
   ],
   "source": [
    "class_vec = torch.zeros(20)\n",
    "weight_vec = torch.ones(20)\n",
    "for item in class_lst:\n",
    "    idx = CLASS_NAMES.index(item[0])\n",
    "    if class_vec[idx] == 1:\n",
    "        weight_vec[idx] = 0 if item[1] == '1' else 1\n",
    "        continue\n",
    "    class_vec[idx] = 1\n",
    "    weight_vec[idx] = 0 if item[1] == '1' else 1\n",
    "\n",
    "print(class_vec)\n",
    "print(weight_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_conv_out_size(inp_size, padding, dilation, kernel_size, stride):\n",
    "        return (inp_size + 2*padding - dilation * (kernel_size-1) - 1)//stride + 1\n",
    "    \n",
    "def _calculate_avg_pool_out_size(inp_size, padding, kernel_size, stride):\n",
    "    return (inp_size + 2*padding - kernel_size)//stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16384\n"
     ]
    }
   ],
   "source": [
    "out_size1 = _calculate_conv_out_size(64, 2, 1, 5, 1)\n",
    "out_size2 = _calculate_avg_pool_out_size(out_size1, 0, 2, 2)\n",
    "out_size3 = _calculate_conv_out_size(out_size2, 2, 1, 5, 1)\n",
    "out_size4 = _calculate_avg_pool_out_size(out_size3, 0, 2, 2)\n",
    "flat_dim = 64 * out_size4 * out_size4\n",
    "print(flat_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.8957)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# logits: [N, C] (raw predictions from the model)\n",
    "# targets: [N, C] (one-hot encoded true labels)\n",
    "N = 3\n",
    "C = 20\n",
    "logits = torch.randn(N, C)  # example logits\n",
    "targets = torch.randint(0, 2, (N, C)).float()  # example one-hot encoded targets\n",
    "weights = torch.randint(0, 2, (N, C)).float()  # example one-hot encoded targets\n",
    "\n",
    "# Calculate the softmax probabilities\n",
    "# softmax_probs = F.softmax(logits, dim=1)\n",
    "softmax_denom = torch.sum(torch.exp(logits-torch.max(logits)), dim=1, keepdims=True)\n",
    "softmax_probs = torch.exp(logits-torch.max(logits)) / softmax_denom\n",
    "\n",
    "# Compute cross-entropy loss\n",
    "loss = -torch.sum(weights * torch.log(softmax_probs) * targets, dim=1).mean()  # per sample\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',\n",
    "                   'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "                   'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "INV_CLASS = {}\n",
    "for i in range(len(CLASS_NAMES)):\n",
    "    INV_CLASS[CLASS_NAMES[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aeroplane': 0,\n",
       " 'bicycle': 1,\n",
       " 'bird': 2,\n",
       " 'boat': 3,\n",
       " 'bottle': 4,\n",
       " 'bus': 5,\n",
       " 'car': 6,\n",
       " 'cat': 7,\n",
       " 'chair': 8,\n",
       " 'cow': 9,\n",
       " 'diningtable': 10,\n",
       " 'dog': 11,\n",
       " 'horse': 12,\n",
       " 'motorbike': 13,\n",
       " 'person': 14,\n",
       " 'pottedplant': 15,\n",
       " 'sheep': 16,\n",
       " 'sofa': 17,\n",
       " 'train': 18,\n",
       " 'tvmonitor': 19}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INV_CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/cmu16824hw1/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import trainer\n",
    "from utils import ARGS\n",
    "from simple_cnn import SimpleCNN\n",
    "from voc_dataset import VOCDataset\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights='IMAGENET1K_V1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=20, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model.fc = nn.Linear(in_features=512, out_features=20)\n",
    "print(model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0189,  0.0221, -0.0231,  ...,  0.0372, -0.0079, -0.0428],\n",
      "        [-0.0165, -0.0285, -0.0409,  ..., -0.0014, -0.0223, -0.0177],\n",
      "        [-0.0172, -0.0369, -0.0080,  ..., -0.0182, -0.0387,  0.0408],\n",
      "        ...,\n",
      "        [-0.0314, -0.0052,  0.0127,  ..., -0.0377,  0.0421, -0.0220],\n",
      "        [-0.0191, -0.0435,  0.0027,  ...,  0.0041, -0.0259, -0.0382],\n",
      "        [ 0.0354, -0.0235, -0.0297,  ..., -0.0293,  0.0349, -0.0180]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0159, -0.0069, -0.0341, -0.0436, -0.0022, -0.0198, -0.0345,  0.0200,\n",
      "         0.0137, -0.0033,  0.0294,  0.0169, -0.0413,  0.0085, -0.0097, -0.0170,\n",
      "        -0.0102, -0.0223, -0.0293, -0.0434], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.fc.parameters():\n",
    "    print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmu16824hw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
